{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e6e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import glob\n",
    "import cv2\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.losses import mse\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "acc0_all = []\n",
    "acc1_all = []\n",
    "num = 150\n",
    "param_nu = 2**(-5)\n",
    "param_ga = 10**(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db087a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 34s 5s/step - loss: 0.6977 - val_loss: 0.6757\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.6481 - val_loss: 0.5848\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.5564 - val_loss: 0.5192\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.5074 - val_loss: 0.4866\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.4780 - val_loss: 0.4585\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.4461 - val_loss: 0.4262\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.4188 - val_loss: 0.4061\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.4041 - val_loss: 0.4074\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.4118 - val_loss: 0.4119\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.4044 - val_loss: 0.3849\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3881 - val_loss: 0.3868\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3820 - val_loss: 0.3760\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3755 - val_loss: 0.3733\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3720 - val_loss: 0.3706\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3697 - val_loss: 0.3683\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3677 - val_loss: 0.3665\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3663 - val_loss: 0.3653\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3654 - val_loss: 0.3644\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3646 - val_loss: 0.3640\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3641 - val_loss: 0.3634\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3636 - val_loss: 0.3631\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3633 - val_loss: 0.3627\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3629 - val_loss: 0.3625\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3627 - val_loss: 0.3623\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3625 - val_loss: 0.3621\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3623 - val_loss: 0.3620\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.3622 - val_loss: 0.3619\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3621 - val_loss: 0.3617\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3619 - val_loss: 0.3616\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3618 - val_loss: 0.3615\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3617 - val_loss: 0.3614\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3616 - val_loss: 0.3613\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3615 - val_loss: 0.3612\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3614 - val_loss: 0.3611\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3614 - val_loss: 0.3610\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3613 - val_loss: 0.3609\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3612 - val_loss: 0.3609\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3611 - val_loss: 0.3608\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3610 - val_loss: 0.3607\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3610 - val_loss: 0.3607\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3609 - val_loss: 0.3606\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.3609 - val_loss: 0.3606\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3608 - val_loss: 0.3605\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 34s 5s/step - loss: 0.3607 - val_loss: 0.3604\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 33s 5s/step - loss: 0.3607 - val_loss: 0.3604\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3606 - val_loss: 0.3603\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3605 - val_loss: 0.3603\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 34s 6s/step - loss: 0.3605 - val_loss: 0.3602\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3605 - val_loss: 0.3603\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3604 - val_loss: 0.3602\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3604 - val_loss: 0.3601\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3603 - val_loss: 0.3600\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3603 - val_loss: 0.3600\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3603 - val_loss: 0.3600\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3602 - val_loss: 0.3599\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3602 - val_loss: 0.3599\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3601 - val_loss: 0.3598\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3601 - val_loss: 0.3598\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3600 - val_loss: 0.3598\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3600 - val_loss: 0.3597\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3599 - val_loss: 0.3598\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3601 - val_loss: 0.3598\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3600 - val_loss: 0.3598\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3600 - val_loss: 0.3596\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3599 - val_loss: 0.3596\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3599 - val_loss: 0.3595\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3595\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3597 - val_loss: 0.3594\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3594\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3594\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3596\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3595\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3597 - val_loss: 0.3594\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3596 - val_loss: 0.3593\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3595 - val_loss: 0.3592\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3595 - val_loss: 0.3592\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3595 - val_loss: 0.3592\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3595 - val_loss: 0.3592\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3594 - val_loss: 0.3592\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3594 - val_loss: 0.3592\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3594 - val_loss: 0.3591\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3594 - val_loss: 0.3591\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 31s 5s/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3594 - val_loss: 0.3590\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3594 - val_loss: 0.3591\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3593 - val_loss: 0.3590\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3592 - val_loss: 0.3590\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.3592 - val_loss: 0.3590\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3593 - val_loss: 0.3591\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3594 - val_loss: 0.3589\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3593 - val_loss: 0.3590\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3593 - val_loss: 0.3589\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3591 - val_loss: 0.3589\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3591 - val_loss: 0.3590\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 28s 4s/step - loss: 0.3591 - val_loss: 0.3589\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3591 - val_loss: 0.3589\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3591 - val_loss: 0.3589\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3592 - val_loss: 0.3589\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3592 - val_loss: 0.3588\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3591 - val_loss: 0.3591\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3594 - val_loss: 0.3589\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3593 - val_loss: 0.3589\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3592 - val_loss: 0.3588\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3591 - val_loss: 0.3589\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3591 - val_loss: 0.3588\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3590 - val_loss: 0.3588\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 27s 4s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3589 - val_loss: 0.3587\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3589 - val_loss: 0.3587\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3589 - val_loss: 0.3587\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3590 - val_loss: 0.3589\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3589 - val_loss: 0.3587\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3589 - val_loss: 0.3588\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3590 - val_loss: 0.3587\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3589 - val_loss: 0.3588\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 33s 6s/step - loss: 0.3589 - val_loss: 0.3587\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 34s 6s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 35s 6s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3589 - val_loss: 0.3586\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 32s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3585\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3588 - val_loss: 0.3586\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3587 - val_loss: 0.3585\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 28s 5s/step - loss: 0.3587 - val_loss: 0.3585\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 30s 5s/step - loss: 0.3587 - val_loss: 0.3584\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3587 - val_loss: 0.3584\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 29s 5s/step - loss: 0.3587 - val_loss: 0.3585\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 31s 5s/step - loss: 0.3588 - val_loss: 0.3592\n",
      "test xentropy: 0.3591572344303131\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 18\n",
      "0 20\n",
      "accuracy: 0.7831325301204819\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3605 - val_loss: 0.3593\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3606 - val_loss: 0.3586\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3599 - val_loss: 0.3586\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3599 - val_loss: 0.3591\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3603 - val_loss: 0.3588\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3601 - val_loss: 0.3586\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3599 - val_loss: 0.3587\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3600 - val_loss: 0.3589\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3602 - val_loss: 0.3588\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3601 - val_loss: 0.3585\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3598 - val_loss: 0.3585\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3598 - val_loss: 0.3587\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3600 - val_loss: 0.3587\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3599 - val_loss: 0.3585\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3598 - val_loss: 0.3586\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3599 - val_loss: 0.3586\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3598 - val_loss: 0.3584\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3598 - val_loss: 0.3586\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3598 - val_loss: 0.3585\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3598 - val_loss: 0.3585\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3585\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3597 - val_loss: 0.3584\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.3596 - val_loss: 0.3584\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3596"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(3):\n",
    "    X_list = glob.glob('bottle/train/good/*.png')\n",
    "    Y_list1 = glob.glob('bottle/test/broken_large/*.png')\n",
    "    Y_list2 = glob.glob('bottle/test/broken_small/*.png')\n",
    "    Y_list3 = glob.glob('bottle/test/contamination/*.png')\n",
    "    Y_list4 = glob.glob('bottle/test/good/*.png')\n",
    "    X_train = None\n",
    "    X_test_good = None\n",
    "    X_test_error = None\n",
    "    for X_file in X_list:\n",
    "      im = cv2.imread(X_file)\n",
    "      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "      im = cv2.resize(im, (256,256))\n",
    "      im = im.reshape(1,im.shape[0],im.shape[1],im.shape[2])\n",
    "      if X_train is not None:\n",
    "        X_train = np.concatenate((X_train, im))\n",
    "      if X_train is None:\n",
    "        X_train = im\n",
    "\n",
    "    for Y_file in Y_list1:\n",
    "      im = cv2.imread(Y_file)\n",
    "      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "      im = cv2.resize(im, (256,256))\n",
    "      im = im.reshape(1,im.shape[0],im.shape[1],im.shape[2])\n",
    "      if X_test_error is not None:\n",
    "        X_test_error = np.concatenate((X_test_error, im))\n",
    "      if X_test_error is None:\n",
    "        X_test_error = im\n",
    "\n",
    "    for Y_file in Y_list2:\n",
    "      im = cv2.imread(Y_file)\n",
    "      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "      im = cv2.resize(im, (256,256))\n",
    "      im = im.reshape(1,im.shape[0],im.shape[1],im.shape[2])\n",
    "      if X_test_error is not None:\n",
    "        X_test_error = np.concatenate((X_test_error, im))\n",
    "      if X_test_error is None:\n",
    "        X_test_error = im\n",
    "\n",
    "    for Y_file in Y_list3:\n",
    "      im = cv2.imread(Y_file)\n",
    "      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "      im = cv2.resize(im, (256,256))\n",
    "      im = im.reshape(1,im.shape[0],im.shape[1],im.shape[2])\n",
    "      if X_test_error is not None:\n",
    "        X_test_error = np.concatenate((X_test_error, im))\n",
    "      if X_test_error is None:\n",
    "        X_test_error = im\n",
    "\n",
    "    for Y_file in Y_list4:\n",
    "      im = cv2.imread(Y_file)\n",
    "      im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "      im = cv2.resize(im, (256,256))\n",
    "      im = im.reshape(1,im.shape[0],im.shape[1],im.shape[2])\n",
    "      if X_test_good is not None:\n",
    "        X_test_good = np.concatenate((X_test_good, im))\n",
    "      if X_test_good is None:\n",
    "        X_test_good = im\n",
    "\n",
    "    X_train = X_train/255\n",
    "    X_test_good = X_test_good/255\n",
    "    X_test_error = X_test_error/255\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.2)\n",
    "\n",
    "\n",
    "    image_height, image_width = 256,256\n",
    "    input_shape = (256,256, 3)\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same',input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(16, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(16, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.add(layers.UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    model.fit(x_train, x_train,epochs=num,batch_size=32,shuffle=True,validation_data=(x_test, x_test))\n",
    "    score = model.evaluate(x_test, x_test, verbose=0)\n",
    "    print('test xentropy:', score)\n",
    "\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_tg = encoder.predict(X_test_good,verbose=0)\n",
    "    X_te = encoder.predict(X_test_error,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_tg = np.reshape(X_tg,(X_tg.shape[0], X_tg.shape[1]*X_tg.shape[2]*X_tg.shape[3]))\n",
    "    x_te = np.reshape(X_te,(X_te.shape[0], X_te.shape[1]*X_te.shape[2]*X_te.shape[3]))\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(x_tr)\n",
    "    f_train = pca.transform(x_tr)\n",
    "\n",
    "    pca.fit(x_tg)\n",
    "    f_test_0 = pca.transform(x_tg)\n",
    "\n",
    "    pca.fit(x_te)\n",
    "    f_test_1 = pca.transform(x_te)\n",
    "\n",
    "    clf = OneClassSVM(nu=param_nu, kernel=\"rbf\", gamma=param_ga)\n",
    "    clf.fit(x_tr)\n",
    "    pred_tr = clf.predict(x_tr)\n",
    "    pred_tg = clf.predict(x_tg)\n",
    "    pred_te = clf.predict(x_te)\n",
    "\n",
    "    index_tr = np.where(pred_tr < 0)\n",
    "    index_tg = np.where(pred_tg < 0)\n",
    "    index_te = np.where(pred_te < 0)\n",
    "\n",
    "    plt.scatter(f_train[:, 0], f_train[:, 1],c='b')\n",
    "    plt.scatter(f_train[index_tr, 0], f_train[index_tr, 1], c='red', label='outlair')\n",
    "\n",
    "    plt.scatter(f_test_0[:, 0], f_test_0[:, 1],c='g')\n",
    "    plt.scatter(f_test_0[index_tg, 0], f_test_0[index_tg, 1], c='red')\n",
    "\n",
    "    plt.scatter(f_test_1[:, 0], f_test_1[:, 1],c='black')\n",
    "    plt.scatter(f_test_1[index_te, 0], f_test_1[index_te, 1], c='red')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('OneClassSVM.png')\n",
    "    plt.show()\n",
    "\n",
    "    in_tg = np.array(index_tg)\n",
    "    in_te = np.array(index_te)\n",
    "\n",
    "    a0, b0 = in_tg.shape\n",
    "    a1, b1 = in_te.shape\n",
    "\n",
    "    TN = len(x_tg) - b0\n",
    "    FP = b0\n",
    "    FN = len(x_te) - b1\n",
    "    TP = b1\n",
    "    print(TP, FN)\n",
    "    print(FP, TN)\n",
    "    a = (TP + TN)/(TP+TN+FP+FN)\n",
    "    acc0_all.append(a)\n",
    "    print('accuracy:',a) \n",
    "\n",
    "    s_v = np.array(clf.support_)\n",
    "    SV = []\n",
    "    for i in range(len(s_v)):\n",
    "        SV.append(list(X_train[s_v[i], :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "\n",
    "    model.fit(sv, sv,epochs=num,batch_size=32,shuffle=True,validation_data=(x_test, x_test))\n",
    "    score = model.evaluate(x_test, x_test, verbose=0)\n",
    "    print('test xentropy:', score)\n",
    "\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_tg = encoder.predict(X_test_good,verbose=0)\n",
    "    X_te = encoder.predict(X_test_error,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_tg = np.reshape(X_tg,(X_tg.shape[0], X_tg.shape[1]*X_tg.shape[2]*X_tg.shape[3]))\n",
    "    x_te = np.reshape(X_te,(X_te.shape[0], X_te.shape[1]*X_te.shape[2]*X_te.shape[3]))\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(x_tr)\n",
    "    f_train = pca.transform(x_tr)\n",
    "\n",
    "    pca.fit(x_tg)\n",
    "    f_test_0 = pca.transform(x_tg)\n",
    "\n",
    "    pca.fit(x_te)\n",
    "    f_test_1 = pca.transform(x_te)\n",
    "\n",
    "\n",
    "    clf.fit(x_tr)\n",
    "    pred_tr_sv = clf.predict(x_tr)\n",
    "    pred_tg_sv = clf.predict(x_tg)\n",
    "    pred_te_sv = clf.predict(x_te)\n",
    "\n",
    "    index_tr_sv = np.where(pred_tr_sv < 0)\n",
    "    index_tg_sv = np.where(pred_tg_sv < 0)\n",
    "    index_te_sv = np.where(pred_te_sv < 0)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(f_train[:, 0], f_train[:, 1],c='b')\n",
    "    plt.scatter(f_train[index_tr_sv, 0], f_train[index_tr_sv, 1], c='red', label='outlair')\n",
    "\n",
    "    plt.scatter(f_test_0[:, 0], f_test_0[:, 1],c='g')\n",
    "    plt.scatter(f_test_0[index_tg_sv, 0], f_test_0[index_tg_sv, 1], c='red')\n",
    "\n",
    "    plt.scatter(f_test_1[:, 0], f_test_1[:, 1],c='black')\n",
    "    plt.scatter(f_test_1[index_te_sv, 0], f_test_1[index_te_sv, 1], c='red')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    in_tg_sv = np.array(index_tg_sv)\n",
    "    in_te_sv = np.array(index_te_sv)\n",
    "\n",
    "    a0, b0 = in_tg_sv.shape\n",
    "    a1, b1 = in_te_sv.shape\n",
    "\n",
    "    TN = len(x_tg) - b0\n",
    "    FP = b0\n",
    "    FN = len(x_te) - b1\n",
    "    TP = b1\n",
    "    print(TP, FN)\n",
    "    print(FP, TN)\n",
    "    a = (TP + TN)/(TP+TN+FP+FN)\n",
    "    acc1_all.append(a)\n",
    "    print('accuracy:',a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f709fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('cal_acc0.csv', acc0_all, delimiter=',')\n",
    "np.savetxt('cal_acc1.csv', acc1_all, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09732a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = statistics.mean(acc0_all)\n",
    "# b = statistics.pstdev(acc0_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('cal_acc1.csv')\n",
    "b = np.loadtxt('cal_acc0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4335bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(a), statistics.pstdev(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf7926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
