{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6083012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras import models, callbacks\n",
    "from sklearn.svm import OneClassSVM\n",
    "from deep_svdd import BaseSVDD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D, Reshape\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.efficientnet import decode_predictions\n",
    "from efficientnet.tfkeras import EfficientNetB2, preprocess_input\n",
    "import MVTecAD_loaddata as mv\n",
    "import pandas as pd\n",
    "AUC_list0=[]\n",
    "AUC_list01=[]\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor='loss', min_delta=10**(-4), patience=2, mode='auto')\n",
    "def makelabels(A):\n",
    "    labels = []\n",
    "    for i in A:\n",
    "        if i == 1:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f6f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "# x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "# data_num = X_train.shape[0]\n",
    "# param_nu = 0.1\n",
    "# param_C =1/(data_num*param_nu)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "# model.add(Reshape((8,8,1408)))\n",
    "# model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "# model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "# model.add(UpSampling2D(size=(2, 2)))\n",
    "# model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "# model.add(UpSampling2D(size=(2, 2)))\n",
    "# model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "# model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "# model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "# encoder = models.clone_model(model)\n",
    "# encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# encoder.set_weights(model.get_weights())\n",
    "# for i in range(7):\n",
    "#     encoder.pop()\n",
    "# X_tr = encoder.predict(X_train,verbose=0)\n",
    "# X_ts = encoder.predict(X_test,verbose=0)\n",
    "# x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "# x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "# svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "# svdd.fit(x_tr)\n",
    "# svdd.predict(x_ts, y_ts)\n",
    "# loss = svdd.get_distance(x_ts)\n",
    "# y_test = makelabels(y_ts)\n",
    "# auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "# AUC_list0.append(auc)\n",
    "\n",
    "# alphas = svdd.alpha\n",
    "# Param = svdd.C\n",
    "# m, n = x_tr.shape\n",
    "# SV = []\n",
    "# NSV = []\n",
    "# for i in range(m):\n",
    "#   if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "#     SV.append(list(X_train[i, :, :, :]))\n",
    "#   else:\n",
    "#     NSV.append(list(X_train[i, :, :, :]))\n",
    "# sv = np.array(SV)\n",
    "# nsv = np.array(NSV)\n",
    "# a, b, c, d = sv.shape\n",
    "# a = a/9.9\n",
    "# a = int(a)\n",
    "# model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "# encoder = models.clone_model(model)\n",
    "# encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# encoder.set_weights(model.get_weights())\n",
    "# for i in range(7):\n",
    "#     encoder.pop()\n",
    "# X_tr = encoder.predict(X_train,verbose=0)\n",
    "# X_ts = encoder.predict(X_test,verbose=0)\n",
    "# x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "# x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "# svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "# svdd.fit(x_tr)\n",
    "# loss = svdd.get_distance(x_ts)\n",
    "# svdd.predict(x_ts, y_ts)\n",
    "# y_test = makelabels(y_ts)\n",
    "# auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "# AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bd4e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1557 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 14\n",
      "radius               = 0.2791\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 24\n",
      "ratio of SVs         = 11.4833 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8335 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 45s 3s/step - loss: 0.1288 - accuracy: 0.4142 - val_loss: 0.1300 - val_accuracy: 0.4157\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.1081 - accuracy: 0.3864 - val_loss: 0.1227 - val_accuracy: 0.3923\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 40s 3s/step - loss: 0.1006 - accuracy: 0.4085 - val_loss: 0.1225 - val_accuracy: 0.4015\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0960 - accuracy: 0.3985 - val_loss: 0.1195 - val_accuracy: 0.3562\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0814 - accuracy: 0.3784 - val_loss: 0.1009 - val_accuracy: 0.3679\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0414 - accuracy: 0.3805 - val_loss: 0.0880 - val_accuracy: 0.3401\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0158 - accuracy: 0.3432 - val_loss: 0.0965 - val_accuracy: 0.3338\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0118 - accuracy: 0.3607 - val_loss: 0.0895 - val_accuracy: 0.3515\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0103 - accuracy: 0.3720 - val_loss: 0.0771 - val_accuracy: 0.3584\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0089 - accuracy: 0.3866 - val_loss: 0.0657 - val_accuracy: 0.3746\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0080 - accuracy: 0.4014 - val_loss: 0.0495 - val_accuracy: 0.3906\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0074 - accuracy: 0.4106 - val_loss: 0.0419 - val_accuracy: 0.4029\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0074 - accuracy: 0.4300 - val_loss: 0.0342 - val_accuracy: 0.4183\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0068 - accuracy: 0.4436 - val_loss: 0.0319 - val_accuracy: 0.4231\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0069 - accuracy: 0.4432 - val_loss: 0.0274 - val_accuracy: 0.4286\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0065 - accuracy: 0.4565 - val_loss: 0.0237 - val_accuracy: 0.4441\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0063 - accuracy: 0.4589 - val_loss: 0.0177 - val_accuracy: 0.4416\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0061 - accuracy: 0.4672 - val_loss: 0.0138 - val_accuracy: 0.4582\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0059 - accuracy: 0.4731 - val_loss: 0.0120 - val_accuracy: 0.4597\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0058 - accuracy: 0.4757 - val_loss: 0.0107 - val_accuracy: 0.4672\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.0960 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6333\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 33\n",
      "ratio of SVs         = 15.7895 %\n",
      "accuracy             = 96.6507 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8502 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 62\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.0719 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 14\n",
      "radius               = 0.2791\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 24\n",
      "ratio of SVs         = 11.4833 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8937 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 46s 3s/step - loss: 0.1305 - accuracy: 0.2510 - val_loss: 0.1300 - val_accuracy: 0.2965\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.1124 - accuracy: 0.3292 - val_loss: 0.1207 - val_accuracy: 0.3512\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0782 - accuracy: 0.3816 - val_loss: 0.1051 - val_accuracy: 0.3620\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0565 - accuracy: 0.4531 - val_loss: 0.0922 - val_accuracy: 0.3942\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0491 - accuracy: 0.5466 - val_loss: 0.0826 - val_accuracy: 0.4532\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0475 - accuracy: 0.5778 - val_loss: 0.0767 - val_accuracy: 0.4930\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0466 - accuracy: 0.5902 - val_loss: 0.0701 - val_accuracy: 0.5272\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0459 - accuracy: 0.5958 - val_loss: 0.0644 - val_accuracy: 0.5451\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0451 - accuracy: 0.5986 - val_loss: 0.0584 - val_accuracy: 0.5590\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0444 - accuracy: 0.5985 - val_loss: 0.0548 - val_accuracy: 0.5659\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0436 - accuracy: 0.5995 - val_loss: 0.0513 - val_accuracy: 0.5715\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0427 - accuracy: 0.6011 - val_loss: 0.0485 - val_accuracy: 0.5765\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0417 - accuracy: 0.6031 - val_loss: 0.0455 - val_accuracy: 0.5784\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0407 - accuracy: 0.6060 - val_loss: 0.0428 - val_accuracy: 0.5819\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0394 - accuracy: 0.6107 - val_loss: 0.0408 - val_accuracy: 0.5820\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0379 - accuracy: 0.6127 - val_loss: 0.0385 - val_accuracy: 0.5806\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0363 - accuracy: 0.6176 - val_loss: 0.0362 - val_accuracy: 0.5801\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0340 - accuracy: 0.6182 - val_loss: 0.0328 - val_accuracy: 0.5780\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0246 - accuracy: 0.5698 - val_loss: 0.0153 - val_accuracy: 0.5120\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0105 - accuracy: 0.5227 - val_loss: 0.0094 - val_accuracy: 0.5135\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1027 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 12\n",
      "radius               = 0.4617\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 33\n",
      "ratio of SVs         = 15.7895 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8479 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 91.5663 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.0752 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 14\n",
      "radius               = 0.2791\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 24\n",
      "ratio of SVs         = 11.4833 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8441 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 46s 3s/step - loss: 0.1291 - accuracy: 0.3394 - val_loss: 0.1301 - val_accuracy: 0.3509\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.1103 - accuracy: 0.3110 - val_loss: 0.1221 - val_accuracy: 0.3155\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.1021 - accuracy: 0.2902 - val_loss: 0.1195 - val_accuracy: 0.3304\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0983 - accuracy: 0.3216 - val_loss: 0.1194 - val_accuracy: 0.3220\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0956 - accuracy: 0.3142 - val_loss: 0.1170 - val_accuracy: 0.3435\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0877 - accuracy: 0.3428 - val_loss: 0.1039 - val_accuracy: 0.3676\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0554 - accuracy: 0.3420 - val_loss: 0.0813 - val_accuracy: 0.3368\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0209 - accuracy: 0.2984 - val_loss: 0.0790 - val_accuracy: 0.3268\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0117 - accuracy: 0.3089 - val_loss: 0.0736 - val_accuracy: 0.3489\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0099 - accuracy: 0.3401 - val_loss: 0.0602 - val_accuracy: 0.3523\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0087 - accuracy: 0.3682 - val_loss: 0.0513 - val_accuracy: 0.3645\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0078 - accuracy: 0.3804 - val_loss: 0.0454 - val_accuracy: 0.3797\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0075 - accuracy: 0.3954 - val_loss: 0.0385 - val_accuracy: 0.3855\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0071 - accuracy: 0.4038 - val_loss: 0.0318 - val_accuracy: 0.3922\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0071 - accuracy: 0.4168 - val_loss: 0.0279 - val_accuracy: 0.3964\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0068 - accuracy: 0.4178 - val_loss: 0.0193 - val_accuracy: 0.4086\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0066 - accuracy: 0.4201 - val_loss: 0.0164 - val_accuracy: 0.4084\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0063 - accuracy: 0.4333 - val_loss: 0.0164 - val_accuracy: 0.4113\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0061 - accuracy: 0.4337 - val_loss: 0.0145 - val_accuracy: 0.4186\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0060 - accuracy: 0.4427 - val_loss: 0.0121 - val_accuracy: 0.4254\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1027 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6145\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 32\n",
      "ratio of SVs         = 15.3110 %\n",
      "accuracy             = 96.6507 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8908 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.0697 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 14\n",
      "radius               = 0.2791\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 24\n",
      "ratio of SVs         = 11.4833 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8787 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 46s 3s/step - loss: 0.1302 - accuracy: 0.4871 - val_loss: 0.1308 - val_accuracy: 0.4922\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.1124 - accuracy: 0.4981 - val_loss: 0.1211 - val_accuracy: 0.4732\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.1019 - accuracy: 0.4399 - val_loss: 0.1196 - val_accuracy: 0.3898\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0982 - accuracy: 0.4293 - val_loss: 0.1200 - val_accuracy: 0.4734\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0952 - accuracy: 0.5310 - val_loss: 0.1175 - val_accuracy: 0.4902\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0847 - accuracy: 0.5285 - val_loss: 0.0996 - val_accuracy: 0.4829\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0466 - accuracy: 0.5265 - val_loss: 0.0715 - val_accuracy: 0.4996\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 40s 4s/step - loss: 0.0172 - accuracy: 0.5514 - val_loss: 0.0644 - val_accuracy: 0.4930\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0111 - accuracy: 0.5434 - val_loss: 0.0537 - val_accuracy: 0.4887\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0095 - accuracy: 0.5419 - val_loss: 0.0504 - val_accuracy: 0.4998\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0087 - accuracy: 0.5497 - val_loss: 0.0402 - val_accuracy: 0.5182\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.0080 - accuracy: 0.5634 - val_loss: 0.0337 - val_accuracy: 0.5416\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.0075 - accuracy: 0.5796 - val_loss: 0.0343 - val_accuracy: 0.5457\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0071 - accuracy: 0.5893 - val_loss: 0.0276 - val_accuracy: 0.5636\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0068 - accuracy: 0.6013 - val_loss: 0.0270 - val_accuracy: 0.5705\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.0065 - accuracy: 0.6030 - val_loss: 0.0269 - val_accuracy: 0.5823\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0063 - accuracy: 0.6179 - val_loss: 0.0255 - val_accuracy: 0.5904\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.0062 - accuracy: 0.6214 - val_loss: 0.0247 - val_accuracy: 0.5987\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0062 - accuracy: 0.6314 - val_loss: 0.0241 - val_accuracy: 0.6046\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0061 - accuracy: 0.6325 - val_loss: 0.0212 - val_accuracy: 0.6176\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1024 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 10\n",
      "radius               = 0.6680\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 37\n",
      "ratio of SVs         = 17.7033 %\n",
      "accuracy             = 96.1722 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.7994 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 65\n",
      "accuracy             = 95.1807 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.0546 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 14\n",
      "radius               = 0.2791\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 24\n",
      "ratio of SVs         = 11.4833 %\n",
      "accuracy             = 95.6938 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8670 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 96.3855 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 45s 3s/step - loss: 0.1184 - accuracy: 0.3312 - val_loss: 0.1254 - val_accuracy: 0.3287\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.1039 - accuracy: 0.3503 - val_loss: 0.1201 - val_accuracy: 0.3614\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.1002 - accuracy: 0.3698 - val_loss: 0.1213 - val_accuracy: 0.3739\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0981 - accuracy: 0.3761 - val_loss: 0.1174 - val_accuracy: 0.3468\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 37s 3s/step - loss: 0.0966 - accuracy: 0.3381 - val_loss: 0.1156 - val_accuracy: 0.3357\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0953 - accuracy: 0.3539 - val_loss: 0.1156 - val_accuracy: 0.3307\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0941 - accuracy: 0.3539 - val_loss: 0.1147 - val_accuracy: 0.3275\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0929 - accuracy: 0.3675 - val_loss: 0.1110 - val_accuracy: 0.3365\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0915 - accuracy: 0.3753 - val_loss: 0.1076 - val_accuracy: 0.3520\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0892 - accuracy: 0.4171 - val_loss: 0.1032 - val_accuracy: 0.3946\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0788 - accuracy: 0.4714 - val_loss: 0.0859 - val_accuracy: 0.4263\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0388 - accuracy: 0.4998 - val_loss: 0.0591 - val_accuracy: 0.4306\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0139 - accuracy: 0.4738 - val_loss: 0.0441 - val_accuracy: 0.4320\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0104 - accuracy: 0.4762 - val_loss: 0.0403 - val_accuracy: 0.4396\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0098 - accuracy: 0.4727 - val_loss: 0.0254 - val_accuracy: 0.4515\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0081 - accuracy: 0.4747 - val_loss: 0.0238 - val_accuracy: 0.4570\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0079 - accuracy: 0.4882 - val_loss: 0.0337 - val_accuracy: 0.4492\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 37s 3s/step - loss: 0.0073 - accuracy: 0.4899 - val_loss: 0.0285 - val_accuracy: 0.4664\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 38s 3s/step - loss: 0.0073 - accuracy: 0.4970 - val_loss: 0.0139 - val_accuracy: 0.4857\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.0068 - accuracy: 0.4999 - val_loss: 0.0093 - val_accuracy: 0.4980\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1026 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.5805\n",
      "number of samples    = 209\n",
      "number of features   = 90112\n",
      "number of SVs        = 32\n",
      "ratio of SVs         = 15.3110 %\n",
      "accuracy             = 95.2153 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 0.8285 seconds\n",
      "number of samples    = 83\n",
      "number of alarm      = 64\n",
      "accuracy             = 93.9759 %\n",
      "\n",
      "\n",
      "Wall time: 1h 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for num in range(1):\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "#     param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "#     model.add(Reshape((8,8,1408)))\n",
    "#     model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "#     model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "#     model.add(UpSampling2D(size=(2, 2)))\n",
    "#     model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "#     model.add(UpSampling2D(size=(2, 2)))\n",
    "#     model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "#     model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "#     encoder = models.clone_model(model)\n",
    "#     encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#     encoder.set_weights(model.get_weights())\n",
    "#     for i in range(7):\n",
    "#         encoder.pop()\n",
    "    X_tr = model.predict(X_train,verbose=0)\n",
    "    X_ts = model.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebc2cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1810 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6088\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 16.9643 %\n",
      "accuracy             = 95.9821 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3036 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 63\n",
      "accuracy             = 76.4286 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 59s 4s/step - loss: 0.0537 - accuracy: 0.3962 - val_loss: 0.0523 - val_accuracy: 0.5656\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0480 - accuracy: 0.6475 - val_loss: 0.0468 - val_accuracy: 0.7016\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0425 - accuracy: 0.7377 - val_loss: 0.0429 - val_accuracy: 0.7803\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0372 - accuracy: 0.7925 - val_loss: 0.0404 - val_accuracy: 0.7992\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0338 - accuracy: 0.7881 - val_loss: 0.0392 - val_accuracy: 0.7988\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0315 - accuracy: 0.7970 - val_loss: 0.0371 - val_accuracy: 0.8100\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0283 - accuracy: 0.8049 - val_loss: 0.0344 - val_accuracy: 0.8034\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0235 - accuracy: 0.8011 - val_loss: 0.0301 - val_accuracy: 0.8059\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0202 - accuracy: 0.8115 - val_loss: 0.0287 - val_accuracy: 0.8169\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0183 - accuracy: 0.8155 - val_loss: 0.0285 - val_accuracy: 0.8168\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0174 - accuracy: 0.8209 - val_loss: 0.0273 - val_accuracy: 0.8246\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0166 - accuracy: 0.8257 - val_loss: 0.0255 - val_accuracy: 0.8307\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0159 - accuracy: 0.8275 - val_loss: 0.0243 - val_accuracy: 0.8302\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0155 - accuracy: 0.8297 - val_loss: 0.0232 - val_accuracy: 0.8381\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0149 - accuracy: 0.8340 - val_loss: 0.0219 - val_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0146 - accuracy: 0.8291 - val_loss: 0.0215 - val_accuracy: 0.8400\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0142 - accuracy: 0.8342 - val_loss: 0.0208 - val_accuracy: 0.8368\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0139 - accuracy: 0.8351 - val_loss: 0.0200 - val_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0136 - accuracy: 0.8359 - val_loss: 0.0187 - val_accuracy: 0.8424\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0134 - accuracy: 0.8380 - val_loss: 0.0182 - val_accuracy: 0.8382\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1878 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 9\n",
      "radius               = 0.8461\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 62\n",
      "ratio of SVs         = 27.6786 %\n",
      "accuracy             = 97.7679 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2810 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 49\n",
      "accuracy             = 70.7143 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2026 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6088\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 16.9643 %\n",
      "accuracy             = 95.9821 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2654 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 63\n",
      "accuracy             = 76.4286 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 58s 4s/step - loss: 0.0532 - accuracy: 0.1357 - val_loss: 0.0515 - val_accuracy: 0.2022\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0480 - accuracy: 0.3542 - val_loss: 0.0471 - val_accuracy: 0.5574\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0427 - accuracy: 0.6530 - val_loss: 0.0427 - val_accuracy: 0.7314\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 50s 4s/step - loss: 0.0377 - accuracy: 0.7527 - val_loss: 0.0394 - val_accuracy: 0.7798\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0344 - accuracy: 0.7746 - val_loss: 0.0382 - val_accuracy: 0.7917\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0325 - accuracy: 0.7803 - val_loss: 0.0370 - val_accuracy: 0.7914\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0312 - accuracy: 0.7824 - val_loss: 0.0359 - val_accuracy: 0.8035\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0300 - accuracy: 0.7880 - val_loss: 0.0350 - val_accuracy: 0.8047\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0285 - accuracy: 0.7836 - val_loss: 0.0326 - val_accuracy: 0.8060\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 49s 4s/step - loss: 0.0259 - accuracy: 0.8013 - val_loss: 0.0292 - val_accuracy: 0.8111\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0222 - accuracy: 0.8062 - val_loss: 0.0259 - val_accuracy: 0.8238\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0194 - accuracy: 0.8170 - val_loss: 0.0241 - val_accuracy: 0.8254\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0176 - accuracy: 0.8205 - val_loss: 0.0219 - val_accuracy: 0.8280\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0163 - accuracy: 0.8249 - val_loss: 0.0210 - val_accuracy: 0.8339\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0159 - accuracy: 0.8273 - val_loss: 0.0205 - val_accuracy: 0.8395\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0150 - accuracy: 0.8313 - val_loss: 0.0199 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0147 - accuracy: 0.8338 - val_loss: 0.0191 - val_accuracy: 0.8440\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0142 - accuracy: 0.8338 - val_loss: 0.0190 - val_accuracy: 0.8412\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 48s 4s/step - loss: 0.0139 - accuracy: 0.8358 - val_loss: 0.0183 - val_accuracy: 0.8417\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0136 - accuracy: 0.8359 - val_loss: 0.0177 - val_accuracy: 0.8464\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.3432 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 9\n",
      "radius               = 0.8407\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 62\n",
      "ratio of SVs         = 27.6786 %\n",
      "accuracy             = 98.2143 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3122 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 69\n",
      "accuracy             = 69.2857 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1714 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6088\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 16.9643 %\n",
      "accuracy             = 95.9821 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2810 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 63\n",
      "accuracy             = 76.4286 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 57s 4s/step - loss: 0.0513 - accuracy: 0.3802 - val_loss: 0.0490 - val_accuracy: 0.5126\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0456 - accuracy: 0.6110 - val_loss: 0.0452 - val_accuracy: 0.6955\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0406 - accuracy: 0.7324 - val_loss: 0.0423 - val_accuracy: 0.7752\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0367 - accuracy: 0.7835 - val_loss: 0.0398 - val_accuracy: 0.7944\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0342 - accuracy: 0.8002 - val_loss: 0.0385 - val_accuracy: 0.8070\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0324 - accuracy: 0.8070 - val_loss: 0.0373 - val_accuracy: 0.8069\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0311 - accuracy: 0.8125 - val_loss: 0.0371 - val_accuracy: 0.8180\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0302 - accuracy: 0.8206 - val_loss: 0.0363 - val_accuracy: 0.8222\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0294 - accuracy: 0.8245 - val_loss: 0.0352 - val_accuracy: 0.8261\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0286 - accuracy: 0.8314 - val_loss: 0.0345 - val_accuracy: 0.8302\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0280 - accuracy: 0.8327 - val_loss: 0.0336 - val_accuracy: 0.8338\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0271 - accuracy: 0.8420 - val_loss: 0.0321 - val_accuracy: 0.8357\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0253 - accuracy: 0.8417 - val_loss: 0.0297 - val_accuracy: 0.8414\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0225 - accuracy: 0.8439 - val_loss: 0.0263 - val_accuracy: 0.8387\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0190 - accuracy: 0.8361 - val_loss: 0.0238 - val_accuracy: 0.8463\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0169 - accuracy: 0.8350 - val_loss: 0.0218 - val_accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0157 - accuracy: 0.8334 - val_loss: 0.0201 - val_accuracy: 0.8319\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0148 - accuracy: 0.8320 - val_loss: 0.0196 - val_accuracy: 0.8398\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 47s 4s/step - loss: 0.0143 - accuracy: 0.8360 - val_loss: 0.0185 - val_accuracy: 0.8414\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 46s 4s/step - loss: 0.0139 - accuracy: 0.8372 - val_loss: 0.0181 - val_accuracy: 0.8429\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2589 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 10\n",
      "radius               = 0.8523\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 60\n",
      "ratio of SVs         = 26.7857 %\n",
      "accuracy             = 97.3214 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2891 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 56\n",
      "accuracy             = 65.7143 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2121 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6088\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 16.9643 %\n",
      "accuracy             = 95.9821 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2746 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 63\n",
      "accuracy             = 76.4286 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 65s 5s/step - loss: 0.0532 - accuracy: 0.5488 - val_loss: 0.0515 - val_accuracy: 0.6308\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0477 - accuracy: 0.6678 - val_loss: 0.0460 - val_accuracy: 0.7062\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0418 - accuracy: 0.7255 - val_loss: 0.0423 - val_accuracy: 0.7685\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0372 - accuracy: 0.7759 - val_loss: 0.0397 - val_accuracy: 0.7988\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0343 - accuracy: 0.7901 - val_loss: 0.0388 - val_accuracy: 0.8024\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0326 - accuracy: 0.7968 - val_loss: 0.0380 - val_accuracy: 0.8075\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0311 - accuracy: 0.8001 - val_loss: 0.0360 - val_accuracy: 0.8093\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0290 - accuracy: 0.7977 - val_loss: 0.0341 - val_accuracy: 0.8067\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0257 - accuracy: 0.7944 - val_loss: 0.0302 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0214 - accuracy: 0.7988 - val_loss: 0.0273 - val_accuracy: 0.8118\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0189 - accuracy: 0.8114 - val_loss: 0.0250 - val_accuracy: 0.8232\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0176 - accuracy: 0.8181 - val_loss: 0.0230 - val_accuracy: 0.8295\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0164 - accuracy: 0.8251 - val_loss: 0.0228 - val_accuracy: 0.8348\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0158 - accuracy: 0.8302 - val_loss: 0.0215 - val_accuracy: 0.8349\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0152 - accuracy: 0.8296 - val_loss: 0.0204 - val_accuracy: 0.8395\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0147 - accuracy: 0.8341 - val_loss: 0.0193 - val_accuracy: 0.8377\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.0145 - accuracy: 0.8329 - val_loss: 0.0189 - val_accuracy: 0.8428\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0140 - accuracy: 0.8364 - val_loss: 0.0187 - val_accuracy: 0.8412\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0136 - accuracy: 0.8373 - val_loss: 0.0179 - val_accuracy: 0.8439\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0134 - accuracy: 0.8367 - val_loss: 0.0177 - val_accuracy: 0.8455\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2750 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 9\n",
      "radius               = 0.8515\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 61\n",
      "ratio of SVs         = 27.2321 %\n",
      "accuracy             = 98.2143 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3041 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 58\n",
      "accuracy             = 72.8571 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1798 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6088\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 16.9643 %\n",
      "accuracy             = 95.9821 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3036 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 63\n",
      "accuracy             = 76.4286 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 64s 4s/step - loss: 0.0528 - accuracy: 0.2414 - val_loss: 0.0511 - val_accuracy: 0.2740\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0475 - accuracy: 0.3207 - val_loss: 0.0464 - val_accuracy: 0.4031\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0418 - accuracy: 0.5083 - val_loss: 0.0425 - val_accuracy: 0.6325\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0369 - accuracy: 0.7145 - val_loss: 0.0393 - val_accuracy: 0.7532\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 52s 4s/step - loss: 0.0341 - accuracy: 0.7610 - val_loss: 0.0379 - val_accuracy: 0.7775\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0324 - accuracy: 0.7862 - val_loss: 0.0382 - val_accuracy: 0.7985\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0310 - accuracy: 0.7986 - val_loss: 0.0369 - val_accuracy: 0.8048\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0297 - accuracy: 0.8061 - val_loss: 0.0365 - val_accuracy: 0.8107\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0280 - accuracy: 0.8166 - val_loss: 0.0342 - val_accuracy: 0.8139\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0248 - accuracy: 0.8196 - val_loss: 0.0293 - val_accuracy: 0.8115\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0208 - accuracy: 0.8155 - val_loss: 0.0255 - val_accuracy: 0.8158\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0183 - accuracy: 0.8180 - val_loss: 0.0237 - val_accuracy: 0.8207\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0165 - accuracy: 0.8167 - val_loss: 0.0223 - val_accuracy: 0.8234\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0158 - accuracy: 0.8223 - val_loss: 0.0208 - val_accuracy: 0.8268\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0152 - accuracy: 0.8240 - val_loss: 0.0201 - val_accuracy: 0.8293\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0146 - accuracy: 0.8272 - val_loss: 0.0193 - val_accuracy: 0.8295\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0141 - accuracy: 0.8263 - val_loss: 0.0192 - val_accuracy: 0.8341\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0138 - accuracy: 0.8312 - val_loss: 0.0186 - val_accuracy: 0.8370\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0134 - accuracy: 0.8306 - val_loss: 0.0185 - val_accuracy: 0.8385\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 52s 4s/step - loss: 0.0133 - accuracy: 0.8367 - val_loss: 0.0178 - val_accuracy: 0.8401\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2124 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 9\n",
      "radius               = 0.8497\n",
      "number of samples    = 224\n",
      "number of features   = 90112\n",
      "number of SVs        = 64\n",
      "ratio of SVs         = 28.5714 %\n",
      "accuracy             = 98.2143 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2868 seconds\n",
      "number of samples    = 140\n",
      "number of alarm      = 55\n",
      "accuracy             = 66.4286 %\n",
      "\n",
      "\n",
      "Wall time: 1h 31min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea3d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2146 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 13\n",
      "radius               = 0.3489\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 28\n",
      "ratio of SVs         = 12.7854 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2396 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 47\n",
      "accuracy             = 46.9697 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 57s 4s/step - loss: 0.0932 - accuracy: 0.2989 - val_loss: 0.0916 - val_accuracy: 0.3346\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0821 - accuracy: 0.3292 - val_loss: 0.0857 - val_accuracy: 0.3381\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0647 - accuracy: 0.3464 - val_loss: 0.0668 - val_accuracy: 0.3308\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0264 - accuracy: 0.3656 - val_loss: 0.0370 - val_accuracy: 0.3602\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0117 - accuracy: 0.4164 - val_loss: 0.0354 - val_accuracy: 0.4160\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0075 - accuracy: 0.4629 - val_loss: 0.0361 - val_accuracy: 0.4549\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0053 - accuracy: 0.4863 - val_loss: 0.0382 - val_accuracy: 0.4578\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0045 - accuracy: 0.4869 - val_loss: 0.0400 - val_accuracy: 0.4387\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0036 - accuracy: 0.4896 - val_loss: 0.0428 - val_accuracy: 0.4347\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.0034 - accuracy: 0.4985 - val_loss: 0.0451 - val_accuracy: 0.4389\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0034 - accuracy: 0.5071 - val_loss: 0.0474 - val_accuracy: 0.4364\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0029 - accuracy: 0.5162 - val_loss: 0.0494 - val_accuracy: 0.4436\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0028 - accuracy: 0.5164 - val_loss: 0.0530 - val_accuracy: 0.4298\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0026 - accuracy: 0.5221 - val_loss: 0.0547 - val_accuracy: 0.4437\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0025 - accuracy: 0.5336 - val_loss: 0.0518 - val_accuracy: 0.4524\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0025 - accuracy: 0.5380 - val_loss: 0.0462 - val_accuracy: 0.4624\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0022 - accuracy: 0.5390 - val_loss: 0.0400 - val_accuracy: 0.4702\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0021 - accuracy: 0.5420 - val_loss: 0.0366 - val_accuracy: 0.4756\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0021 - accuracy: 0.5469 - val_loss: 0.0343 - val_accuracy: 0.4887\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1801 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6327\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 29\n",
      "ratio of SVs         = 13.2420 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2404 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 33\n",
      "accuracy             = 40.9091 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1808 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 13\n",
      "radius               = 0.3489\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 28\n",
      "ratio of SVs         = 12.7854 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2688 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 47\n",
      "accuracy             = 46.9697 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 50s 3s/step - loss: 0.0841 - accuracy: 0.3764 - val_loss: 0.0859 - val_accuracy: 0.3719\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.0474 - accuracy: 0.3869 - val_loss: 0.0680 - val_accuracy: 0.4044\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0305 - accuracy: 0.4278 - val_loss: 0.0593 - val_accuracy: 0.4555\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0270 - accuracy: 0.4435 - val_loss: 0.0561 - val_accuracy: 0.4337\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0244 - accuracy: 0.4274 - val_loss: 0.0571 - val_accuracy: 0.4085\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0230 - accuracy: 0.4339 - val_loss: 0.0577 - val_accuracy: 0.4163\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0224 - accuracy: 0.4611 - val_loss: 0.0583 - val_accuracy: 0.4325\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0224 - accuracy: 0.4614 - val_loss: 0.0572 - val_accuracy: 0.4267\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0221 - accuracy: 0.4658 - val_loss: 0.0565 - val_accuracy: 0.4363\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0220 - accuracy: 0.4844 - val_loss: 0.0596 - val_accuracy: 0.4418\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0219 - accuracy: 0.4900 - val_loss: 0.0636 - val_accuracy: 0.4417\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.0216 - accuracy: 0.4871 - val_loss: 0.0632 - val_accuracy: 0.4500\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0214 - accuracy: 0.5032 - val_loss: 0.0624 - val_accuracy: 0.4568\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0212 - accuracy: 0.5077 - val_loss: 0.0636 - val_accuracy: 0.4597\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0210 - accuracy: 0.4975 - val_loss: 0.0637 - val_accuracy: 0.4688\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0209 - accuracy: 0.5175 - val_loss: 0.0645 - val_accuracy: 0.4783\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0207 - accuracy: 0.5164 - val_loss: 0.0656 - val_accuracy: 0.4780\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0205 - accuracy: 0.5151 - val_loss: 0.0669 - val_accuracy: 0.4790\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0203 - accuracy: 0.5244 - val_loss: 0.0675 - val_accuracy: 0.4856\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0201 - accuracy: 0.5212 - val_loss: 0.0669 - val_accuracy: 0.4846\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1957 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 12\n",
      "radius               = 0.6536\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 25\n",
      "ratio of SVs         = 11.4155 %\n",
      "accuracy             = 96.3470 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3961 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 20\n",
      "accuracy             = 31.0606 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1812 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 13\n",
      "radius               = 0.3489\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 28\n",
      "ratio of SVs         = 12.7854 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3230 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 47\n",
      "accuracy             = 46.9697 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.0902 - accuracy: 0.4206 - val_loss: 0.0883 - val_accuracy: 0.4222\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0587 - accuracy: 0.4041 - val_loss: 0.0755 - val_accuracy: 0.3323\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0330 - accuracy: 0.3340 - val_loss: 0.0651 - val_accuracy: 0.3299\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0286 - accuracy: 0.3769 - val_loss: 0.0619 - val_accuracy: 0.3947\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0255 - accuracy: 0.4362 - val_loss: 0.0579 - val_accuracy: 0.4398\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0237 - accuracy: 0.4502 - val_loss: 0.0554 - val_accuracy: 0.4233\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0233 - accuracy: 0.4543 - val_loss: 0.0577 - val_accuracy: 0.4287\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0227 - accuracy: 0.4661 - val_loss: 0.0585 - val_accuracy: 0.4395\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0220 - accuracy: 0.4736 - val_loss: 0.0597 - val_accuracy: 0.4453\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0220 - accuracy: 0.4789 - val_loss: 0.0615 - val_accuracy: 0.4581\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0218 - accuracy: 0.4834 - val_loss: 0.0626 - val_accuracy: 0.4619\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0215 - accuracy: 0.4977 - val_loss: 0.0646 - val_accuracy: 0.4796\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0216 - accuracy: 0.4957 - val_loss: 0.0649 - val_accuracy: 0.4776\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0213 - accuracy: 0.5026 - val_loss: 0.0647 - val_accuracy: 0.4918\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0212 - accuracy: 0.5048 - val_loss: 0.0648 - val_accuracy: 0.4925\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0210 - accuracy: 0.5156 - val_loss: 0.0665 - val_accuracy: 0.5023\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0209 - accuracy: 0.5171 - val_loss: 0.0675 - val_accuracy: 0.5035\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0206 - accuracy: 0.5118 - val_loss: 0.0671 - val_accuracy: 0.5073\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 50s 4s/step - loss: 0.0206 - accuracy: 0.5237 - val_loss: 0.0667 - val_accuracy: 0.5152\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 49s 4s/step - loss: 0.0205 - accuracy: 0.5311 - val_loss: 0.0674 - val_accuracy: 0.5213\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1895 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 12\n",
      "radius               = 0.5686\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 33\n",
      "ratio of SVs         = 15.0685 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2654 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 27\n",
      "accuracy             = 33.3333 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2651 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 13\n",
      "radius               = 0.3489\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 28\n",
      "ratio of SVs         = 12.7854 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2966 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 47\n",
      "accuracy             = 46.9697 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 56s 4s/step - loss: 0.0903 - accuracy: 0.4855 - val_loss: 0.0875 - val_accuracy: 0.5129\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.0583 - accuracy: 0.5219 - val_loss: 0.0711 - val_accuracy: 0.5017\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.0319 - accuracy: 0.4830 - val_loss: 0.0576 - val_accuracy: 0.4414\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.0277 - accuracy: 0.4273 - val_loss: 0.0564 - val_accuracy: 0.4026\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0248 - accuracy: 0.4396 - val_loss: 0.0565 - val_accuracy: 0.4321\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0234 - accuracy: 0.4545 - val_loss: 0.0586 - val_accuracy: 0.4300\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0226 - accuracy: 0.4634 - val_loss: 0.0581 - val_accuracy: 0.4387\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0221 - accuracy: 0.4756 - val_loss: 0.0555 - val_accuracy: 0.4405\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0218 - accuracy: 0.4833 - val_loss: 0.0567 - val_accuracy: 0.4527\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0218 - accuracy: 0.4921 - val_loss: 0.0582 - val_accuracy: 0.4580\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 48s 4s/step - loss: 0.0212 - accuracy: 0.4938 - val_loss: 0.0600 - val_accuracy: 0.4661\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0207 - accuracy: 0.5014 - val_loss: 0.0625 - val_accuracy: 0.4722\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0183 - accuracy: 0.4903 - val_loss: 0.0620 - val_accuracy: 0.4545\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0098 - accuracy: 0.4752 - val_loss: 0.0612 - val_accuracy: 0.4255\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0047 - accuracy: 0.4571 - val_loss: 0.0619 - val_accuracy: 0.4489\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0038 - accuracy: 0.5049 - val_loss: 0.0629 - val_accuracy: 0.4708\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0033 - accuracy: 0.5091 - val_loss: 0.0639 - val_accuracy: 0.4792\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0029 - accuracy: 0.5119 - val_loss: 0.0641 - val_accuracy: 0.4828\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 47s 4s/step - loss: 0.0027 - accuracy: 0.5156 - val_loss: 0.0633 - val_accuracy: 0.4936\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.0024 - accuracy: 0.5257 - val_loss: 0.0624 - val_accuracy: 0.4815\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1870 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.6226\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 30\n",
      "ratio of SVs         = 13.6986 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2497 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 20\n",
      "accuracy             = 28.0303 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.1870 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 13\n",
      "radius               = 0.3489\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 28\n",
      "ratio of SVs         = 12.7854 %\n",
      "accuracy             = 95.8904 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2497 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 47\n",
      "accuracy             = 46.9697 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.0850 - accuracy: 0.4410 - val_loss: 0.0846 - val_accuracy: 0.4416\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0479 - accuracy: 0.4364 - val_loss: 0.0663 - val_accuracy: 0.3993\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0305 - accuracy: 0.4175 - val_loss: 0.0577 - val_accuracy: 0.3860\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0267 - accuracy: 0.4371 - val_loss: 0.0558 - val_accuracy: 0.4087\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0242 - accuracy: 0.4618 - val_loss: 0.0554 - val_accuracy: 0.4239\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 51s 4s/step - loss: 0.0229 - accuracy: 0.4641 - val_loss: 0.0565 - val_accuracy: 0.4188\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0226 - accuracy: 0.4696 - val_loss: 0.0579 - val_accuracy: 0.4251\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0222 - accuracy: 0.4759 - val_loss: 0.0571 - val_accuracy: 0.4357\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0219 - accuracy: 0.4928 - val_loss: 0.0582 - val_accuracy: 0.4341\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0220 - accuracy: 0.4873 - val_loss: 0.0604 - val_accuracy: 0.4214\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 51s 4s/step - loss: 0.0218 - accuracy: 0.4969 - val_loss: 0.0626 - val_accuracy: 0.4376\n",
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.2026 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 11\n",
      "radius               = 0.8010\n",
      "number of samples    = 219\n",
      "number of features   = 90112\n",
      "number of SVs        = 38\n",
      "ratio of SVs         = 17.3516 %\n",
      "accuracy             = 96.3470 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.2341 seconds\n",
      "number of samples    = 132\n",
      "number of alarm      = 19\n",
      "accuracy             = 27.2727 %\n",
      "\n",
      "\n",
      "Wall time: 1h 18min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8644dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Fitting of the SVDD model is completed. ***\n",
      "\n",
      "running time         = 2.7962 seconds\n",
      "kernel function      = rbf\n",
      "iterations           = 8\n",
      "radius               = 0.1431\n",
      "number of samples    = 280\n",
      "number of features   = 90112\n",
      "number of SVs        = 36\n",
      "ratio of SVs         = 12.8571 %\n",
      "accuracy             = 95.3571 %\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*** Prediction of the provided data is completed. ***\n",
      "\n",
      "running time         = 1.3841 seconds\n",
      "number of samples    = 136\n",
      "number of alarm      = 107\n",
      "accuracy             = 81.6176 %\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 75s 6s/step - loss: 0.0386 - accuracy: 0.1974 - val_loss: 0.0374 - val_accuracy: 0.1687\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 57s 5s/step - loss: 0.0356 - accuracy: 0.1630 - val_loss: 0.0338 - val_accuracy: 0.1368\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 57s 5s/step - loss: 0.0288 - accuracy: 0.1542 - val_loss: 0.0276 - val_accuracy: 0.1565\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 57s 5s/step - loss: 0.0228 - accuracy: 0.2551 - val_loss: 0.0287 - val_accuracy: 0.3418\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.4144"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ab9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeba3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e96749",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cda6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb611c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = sv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(sv, sv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca56972",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(AUC_list)\n",
    "a= a.reshape(15,2)\n",
    "df = pd.DataFrame(a)\n",
    "df.to_csv('EN_SVDD_sv01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c9ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras import models, callbacks\n",
    "from sklearn.svm import OneClassSVM\n",
    "from deep_svdd import BaseSVDD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D, Reshape\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.efficientnet import decode_predictions\n",
    "from efficientnet.tfkeras import EfficientNetB2, preprocess_input\n",
    "import MVTecAD_loaddata as mv\n",
    "import pandas as pd\n",
    "AUC_list0=[]\n",
    "AUC_list01=[]\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor='loss', min_delta=10**(-4), patience=2, mode='auto')\n",
    "def makelabels(A):\n",
    "    labels = []\n",
    "    for i in A:\n",
    "        if i == 1:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c39cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd70f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f089d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b242a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e180ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e91df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for num in range(5):\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.bottle()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.cable()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.capsule()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.carpet()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.grid()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.hazelnut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.leather()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.metal_nut()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.pill()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.screw()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.tile()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.toothbrush()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.transistor()\n",
    "#     X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.wood()\n",
    "    X_train, X_test, X_test_good, X_test_error, y_tr, y_tg, y_te, y_ts = mv.zipper()\n",
    "    x_train, x_test = train_test_split(X_train, test_size=0.1)\n",
    "    data_num = X_train.shape[0]\n",
    "    param_nu = 0.1\n",
    "    param_C =1/(data_num*param_nu)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test_error = X_test_error.astype('float32')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB2(include_top=False,weights='imagenet', input_shape=(256,256,3)))\n",
    "    model.add(Reshape((8,8,1408)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3),activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(3, 3),activation='relu', padding='same',strides=2))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3),activation='sigmoid', padding='same'))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list0.append(auc)\n",
    "\n",
    "    alphas = svdd.alpha\n",
    "    Param = svdd.C\n",
    "    m, n = x_tr.shape\n",
    "    SV = []\n",
    "    NSV = []\n",
    "    for i in range(m):\n",
    "      if alphas[i] > 0 and alphas[i] <= Param[0]:\n",
    "        SV.append(list(X_train[i, :, :, :]))\n",
    "      else:\n",
    "        NSV.append(list(X_train[i, :, :, :]))\n",
    "    sv = np.array(SV)\n",
    "    nsv = np.array(NSV)\n",
    "    a, b, c, d = nsv.shape\n",
    "    a = a/9.9\n",
    "    a = int(a)\n",
    "    model.fit(nsv, nsv,epochs=20,batch_size=a,shuffle=True,validation_data=(X_train, X_train),callbacks=[es_cb])\n",
    "    encoder = models.clone_model(model)\n",
    "    encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    encoder.set_weights(model.get_weights())\n",
    "    for i in range(7):\n",
    "        encoder.pop()\n",
    "    X_tr = encoder.predict(X_train,verbose=0)\n",
    "    X_ts = encoder.predict(X_test,verbose=0)\n",
    "    x_tr = np.reshape(X_tr,(X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]*X_tr.shape[3]))\n",
    "    x_ts = np.reshape(X_ts,(X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]*X_ts.shape[3]))\n",
    "\n",
    "    svdd = BaseSVDD(C=param_C, gamma='scale', kernel='rbf', display='on')\n",
    "    svdd.fit(x_tr)\n",
    "    loss = svdd.get_distance(x_ts)\n",
    "    svdd.predict(x_ts, y_ts)\n",
    "    y_test = makelabels(y_ts)\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test, loss)\n",
    "    AUC_list01.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(AUC_list)\n",
    "a= a.reshape(15,2)\n",
    "df = pd.DataFrame(a)\n",
    "df.to_csv('EN_SVDD_nsv01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(AUC_list01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796b1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
